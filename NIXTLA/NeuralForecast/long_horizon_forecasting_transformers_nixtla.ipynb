{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nixtlaverse.nixtla.io/neuralforecast/docs/tutorials/longhorizon_transformers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasetsforecast.long_horizon import LongHorizon\n",
    "\n",
    "from neuralforecast.core import NeuralForecast\n",
    "from neuralforecast.models import Informer, Autoformer, FEDformer, PatchTST\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       unique_id                  ds         y\n",
      "0           HUFL 2016-07-01 00:00:00 -0.041413\n",
      "1           HUFL 2016-07-01 00:15:00 -0.185467\n",
      "57600       HULL 2016-07-01 00:00:00  0.040104\n",
      "57601       HULL 2016-07-01 00:15:00 -0.214450\n",
      "115200      LUFL 2016-07-01 00:00:00  0.695804\n",
      "115201      LUFL 2016-07-01 00:15:00  0.434685\n",
      "172800      LULL 2016-07-01 00:00:00  0.434430\n",
      "172801      LULL 2016-07-01 00:15:00  0.428168\n",
      "230400      MUFL 2016-07-01 00:00:00 -0.599211\n",
      "230401      MUFL 2016-07-01 00:15:00 -0.658068\n",
      "288000      MULL 2016-07-01 00:00:00 -0.393536\n",
      "288001      MULL 2016-07-01 00:15:00 -0.659338\n",
      "345600        OT 2016-07-01 00:00:00  1.018032\n",
      "345601        OT 2016-07-01 00:15:00  0.980124\n"
     ]
    }
   ],
   "source": [
    "data_path = \"/Users/pepijnschouten/Desktop/Python_Scripts/\" \\\n",
    "    \"Python_scripts_Varia/Deep_Learning/NIXTLA/data\"\n",
    "\n",
    "Y_df, _, _ = LongHorizon.load(directory=data_path, group='ETTm2')\n",
    "Y_df['ds'] = pd.to_datetime(Y_df['ds'])\n",
    "\n",
    "n_time = len(Y_df.ds.unique())\n",
    "val_size = int(.2 * n_time)\n",
    "test_size = int(.2 * n_time)\n",
    "\n",
    "print(Y_df.groupby('unique_id').head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definitions and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:lightning_fabric.utilities.seed:Seed set to 1\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 1\n",
      "INFO:lightning_fabric.utilities.seed:Seed set to 1\n"
     ]
    }
   ],
   "source": [
    "horizon = 4 * 14\n",
    "models = [Informer(\n",
    "    h=horizon,                 \n",
    "    input_size=horizon,           \n",
    "    max_steps=1000,               \n",
    "    val_check_steps=100,          \n",
    "    early_stop_patience_steps=3,\n",
    "    gpu=False,\n",
    "    ),\n",
    "          Autoformer(\n",
    "    h=horizon,\n",
    "    input_size=horizon,\n",
    "    max_steps=1000,\n",
    "    val_check_steps=100,\n",
    "    early_stop_patience_steps=3,\n",
    "    gpu=False,\n",
    "    ),\n",
    "          PatchTST(\n",
    "    h=horizon,\n",
    "    input_size=horizon,\n",
    "    max_steps=1000,\n",
    "    val_check_steps=100,\n",
    "    early_stop_patience_steps=3,\n",
    "    gpu=False,\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Trainer.__init__() got an unexpected keyword argument 'gpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m nf \u001b[38;5;241m=\u001b[39m NeuralForecast(\n\u001b[1;32m      2\u001b[0m     models\u001b[38;5;241m=\u001b[39mmodels,\n\u001b[1;32m      3\u001b[0m     freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m15min\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 6\u001b[0m Y_hat_df \u001b[38;5;241m=\u001b[39m \u001b[43mnf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcross_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mY_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_windows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(Y_hat_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nixtla/lib/python3.12/site-packages/neuralforecast/core.py:1241\u001b[0m, in \u001b[0;36mNeuralForecast.cross_validation\u001b[0;34m(self, df, static_df, n_windows, step_size, val_size, test_size, sort_df, use_init_models, verbose, refit, id_col, time_col, target_col, prediction_intervals, level, **data_kwargs)\u001b[0m\n\u001b[1;32m   1235\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m   1236\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing prediction_intervals and/or level is only supported with refit=True.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1237\u001b[0m         )\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m refit:\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_refit_cross_validation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatic_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatic_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_windows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_windows\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1248\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort_df\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mid_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mid_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1251\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtime_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtime_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1252\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mdata_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust specify `df` with `refit!=False`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nixtla/lib/python3.12/site-packages/neuralforecast/core.py:1083\u001b[0m, in \u001b[0;36mNeuralForecast._no_refit_cross_validation\u001b[0;34m(self, df, static_df, n_windows, step_size, val_size, test_size, sort_df, verbose, id_col, time_col, target_col, **data_kwargs)\u001b[0m\n\u001b[1;32m   1076\u001b[0m fcsts \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfull(\n\u001b[1;32m   1077\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mn_groups \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mh \u001b[38;5;241m*\u001b[39m n_windows, \u001b[38;5;28mlen\u001b[39m(cols)),\n\u001b[1;32m   1078\u001b[0m     np\u001b[38;5;241m.\u001b[39mnan,\n\u001b[1;32m   1079\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[1;32m   1080\u001b[0m )\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodels:\n\u001b[0;32m-> 1083\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1084\u001b[0m     model_fcsts \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(\n\u001b[1;32m   1085\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, step_size\u001b[38;5;241m=\u001b[39mstep_size, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata_kwargs\n\u001b[1;32m   1086\u001b[0m     )\n\u001b[1;32m   1088\u001b[0m     \u001b[38;5;66;03m# Append predictions in memory placeholder\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nixtla/lib/python3.12/site-packages/neuralforecast/common/_base_windows.py:663\u001b[0m, in \u001b[0;36mBaseWindows.fit\u001b[0;34m(self, dataset, val_size, test_size, random_seed, distributed_config)\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    636\u001b[0m     dataset,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    640\u001b[0m     distributed_config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    641\u001b[0m ):\n\u001b[1;32m    642\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit.\u001b[39;00m\n\u001b[1;32m    643\u001b[0m \n\u001b[1;32m    644\u001b[0m \u001b[38;5;124;03m    The `fit` method, optimizes the neural network's weights using the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;124;03m    `test_size`: int, test size for temporal cross-validation.<br>\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalid_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdistributed_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdistributed_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nixtla/lib/python3.12/site-packages/neuralforecast/common/_base_model.py:369\u001b[0m, in \u001b[0;36mBaseModel._fit\u001b[0;34m(self, dataset, batch_size, valid_batch_size, val_size, test_size, random_seed, shuffle_train, distributed_config)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_local:\n\u001b[1;32m    368\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 369\u001b[0m     trainer \u001b[38;5;241m=\u001b[39m \u001b[43mpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    370\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mfit(model, datamodule\u001b[38;5;241m=\u001b[39mdatamodule)\n\u001b[1;32m    371\u001b[0m     model\u001b[38;5;241m.\u001b[39mmetrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mcallback_metrics\n",
      "File \u001b[0;32m/opt/miniconda3/envs/nixtla/lib/python3.12/site-packages/pytorch_lightning/utilities/argparse.py:70\u001b[0m, in \u001b[0;36m_defaults_from_env_vars.<locals>.insert_env_defaults\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mlist\u001b[39m(env_variables\u001b[38;5;241m.\u001b[39mitems()) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mitems()))\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# all args were already moved to kwargs\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Trainer.__init__() got an unexpected keyword argument 'gpu'"
     ]
    }
   ],
   "source": [
    "nf = NeuralForecast(\n",
    "    models=models,\n",
    "    freq='15min',\n",
    ")\n",
    "\n",
    "Y_hat_df = nf.cross_validation(\n",
    "    df=Y_df,\n",
    "    val_size=val_size,\n",
    "    test_size=test_size,\n",
    "    n_windows=None,\n",
    "    \n",
    ")\n",
    "\n",
    "print(Y_hat_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat_df = Y_hat_df.reset_index()\n",
    "Y_plot = Y_hat_df[Y_hat_df['unique_id']=='OT'] # OT dataset\n",
    "cutoffs = Y_hat_df['cutoff'].unique()[::horizon]\n",
    "Y_plot = Y_plot[Y_hat_df['cutoff'].isin(cutoffs)]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(Y_plot['ds'], Y_plot['y'], label='True')\n",
    "plt.plot(Y_plot['ds'], Y_plot['Informer'], label='Informer')\n",
    "plt.plot(Y_plot['ds'], Y_plot['Autoformer'], label='Autoformer')\n",
    "plt.plot(Y_plot['ds'], Y_plot['PatchTST'], label='PatchTST')\n",
    "plt.xlabel('Datestamp')\n",
    "plt.ylabel('OT')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nixtla",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
