{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "DEVICE = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create example data\n",
    "def create_example_data(batch_size, seq_length,\n",
    "                        input_size, device, horizon, trend=False):\n",
    "    # Generate random frequencies and phases (0, 10) (0, 2*pi)\n",
    "    frequencies = torch.rand(batch_size) * 10  \n",
    "    phases = torch.rand(batch_size) * 2 * math.pi  \n",
    "\n",
    "    # Create a time vector (+ target)\n",
    "    time = torch.linspace(0, 2 * math.pi, seq_length + horizon)\n",
    "\n",
    "    # Generate sine waves (+ target)\n",
    "    sine_waves = torch.zeros(batch_size, seq_length + horizon)\n",
    "    for i in range(batch_size):\n",
    "        sine_waves[i] = (torch.sin(frequencies[i] * time + phases[i]))\n",
    "    \n",
    "    if trend:\n",
    "        sine_waves += torch.linspace(0, 2 * math.pi, seq_length + horizon)\n",
    "                \n",
    "    \n",
    "    # add additive amplitude noise to features\n",
    "    sine_waves[:, :-horizon] +=  torch.rand(batch_size, seq_length) / 2\n",
    "    \n",
    "    # Split into inputs and targets\n",
    "    sine_waves = sine_waves[:, :, None]\n",
    "    inputs = sine_waves[:, :-horizon].to(device)\n",
    "    if horizon > 1:\n",
    "        targets = sine_waves[:, -horizon:].to(device)\n",
    "    else:\n",
    "        targets = sine_waves[:, -1].unsqueeze(-1).to(device)\n",
    "  \n",
    "    return sine_waves, inputs, targets, time\n",
    "\n",
    "# Generate example data\n",
    "sine_waves, example_input, example_target, time = create_example_data(\n",
    "    batch_size=32,\n",
    "    seq_length=20,\n",
    "    input_size=1,\n",
    "    device=DEVICE,\n",
    "    horizon=3,\n",
    "    trend=True)\n",
    "\n",
    "print(example_input.shape, example_target.shape, time.shape)\n",
    "\n",
    "# plot example data\n",
    "plt.figure()\n",
    "\n",
    "for i in np.random.randint(0, len(example_input), 5):\n",
    "    plt.plot(\n",
    "        time,\n",
    "        sine_waves[i].squeeze().cpu().detach().numpy(),\n",
    "        'b-')\n",
    "    plt.plot(\n",
    "        time[-3:],\n",
    "        sine_waves[i][-3:].squeeze().cpu().detach().numpy(),\n",
    "        'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Informer (transformer) model \n",
    "for long sequences\n",
    "\n",
    "includes ProbSparse-Attention, PosEnc, enc-dec model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positional encoding\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len, device):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model\n",
    "        ).to(device)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float\n",
    "        ).unsqueeze(1).to(device)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model)\n",
    "        ).to(device)\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ProbSparse Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProbSparse Attention\n",
    "class ProbSparseAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, sparse_factor=0.1, dropout=0.1):\n",
    "        super(ProbSparseAttention, self).__init__()\n",
    "\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.scale = math.sqrt(self.d_k)\n",
    "        self.sparse_factor = sparse_factor\n",
    "        \n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, d_model)\n",
    "        self.value = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, Q, K, V):\n",
    "        \n",
    "        # calculate dimension\n",
    "        batch_size = Q.size(0)\n",
    "        q_len, k_len, v_len = Q.size(1), K.size(1), V.size(1)\n",
    "        \n",
    "        Q = self.query(Q) # (batch_size, seq_len, d_model)\n",
    "        K = self.key(K) # (batch_size, seq_len, d_model)\n",
    "        V = self.value(V) # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        Q = Q.view(batch_size, q_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        K = K.view(batch_size, k_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        V = V.view(batch_size, v_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale # (batch_size, num_heads, seq_len, seq_len)\n",
    "        \n",
    "        # number of top-k\n",
    "        top_k = int(self.sparse_factor * q_len)\n",
    "        if top_k < 1:\n",
    "            top_k = 1\n",
    "        \n",
    "        # mask to scores to attent to top-k\n",
    "        top_k_scores, _ = scores.topk(k=top_k, dim=-1)\n",
    "        threshold = top_k_scores[:, :, :, -1].unsqueeze(-1)\n",
    "        \n",
    "        sparse_mask = scores >= threshold\n",
    "        sparse_scores = scores.masked_fill(sparse_mask, float('-inf'))\n",
    "        \n",
    "        # calculate attention\n",
    "        attention_weights = self.dropout(self.softmax(sparse_scores))\n",
    "        output = torch.matmul(attention_weights, V)\n",
    "        \n",
    "        # recover input shape\n",
    "        output = output.transpose(1, 2).contiguous().view(batch_size, q_len, -1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Block\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        # ProbSparse Attention\n",
    "        self.attention = ProbSparseAttention(d_model, num_heads)\n",
    "        \n",
    "        # Feed-forward residual block\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # ProbSparse Attention\n",
    "        attn_output = self.attention(x, x, x)\n",
    "        \n",
    "        # normalization\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Feed-forward residual block\n",
    "        ffn_output = self.ffn(x)\n",
    "        \n",
    "        # normalization\n",
    "        x = self.norm2(x + self.dropout(ffn_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        # ProbSparse Attention\n",
    "        self.attention = ProbSparseAttention(d_model, num_heads)\n",
    "        \n",
    "        # Feed-forward residual block\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        \n",
    "        # Layer normalization\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, encoder_output):\n",
    "        \n",
    "        # ProbSparse Attention\n",
    "        attn_output = self.attention(x, encoder_output, encoder_output)  \n",
    "             \n",
    "        # normalization\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Feed-forward residual block\n",
    "        ffn_output = self.ffn(x)\n",
    "        \n",
    "        # normalization\n",
    "        x = self.norm2(x + self.dropout(ffn_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full informer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informer Model\n",
    "class Informer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 d_ff,\n",
    "                 num_enc_layers,\n",
    "                 num_dec_layers,\n",
    "                 output_dim,\n",
    "                 seq_len,\n",
    "                 dropout=0.1,\n",
    "                 device='cpu'):\n",
    "        super(Informer, self).__init__()\n",
    "        self.input_embedding = nn.Linear(input_dim, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, seq_len, device)\n",
    "        \n",
    "        # x number of encoder and decoder layers\n",
    "        self.encoder = nn.ModuleList([Encoder(d_model, num_heads, d_ff, dropout) for _ in range(num_enc_layers)])\n",
    "        self.decoder = nn.ModuleList([Decoder(d_model, num_heads, d_ff, dropout) for _ in range(num_dec_layers)])\n",
    "        \n",
    "        # output layer\n",
    "        self.output_layer = nn.Linear(d_model, output_dim)\n",
    "    \n",
    "    def forward(self, x_enc, x_dec):\n",
    "        \n",
    "        # get last time step as input for decoder\n",
    "        x_dec = x_enc[:, -1:, :]\n",
    "        \n",
    "        \n",
    "        # Encoder input processing\n",
    "        enc_out = self.input_embedding(x_enc)\n",
    "        enc_out = self.positional_encoding(enc_out)\n",
    "        # encoder layers\n",
    "        for layer in self.encoder:\n",
    "            enc_out = layer(enc_out)\n",
    "            \n",
    "        # Decoder input processing\n",
    "        dec_out = self.input_embedding(x_dec)\n",
    "        # dec_out = self.positional_encoding(dec_out)\n",
    "        \n",
    "        # Decoder layers (x_enc, x_dec)\n",
    "        for layer in self.decoder:\n",
    "            dec_out = layer(dec_out, enc_out)\n",
    "            \n",
    "        # Output layer\n",
    "        output = self.output_layer(dec_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and test the model\n",
    "model = Informer(input_dim=1,\n",
    "                 d_model=64,\n",
    "                 num_heads=4,\n",
    "                 d_ff=256,\n",
    "                 num_enc_layers=2,\n",
    "                 num_dec_layers=2,\n",
    "                 output_dim=1,\n",
    "                 seq_len=100)\n",
    "\n",
    "print(model)\n",
    "\n",
    "x_enc = torch.randn(32, 100, 1)  # (batch_szie, sequence_len, input dim)\n",
    "x_dec = torch.randn(32, 10, 1)  # Decoder input\n",
    "output = model(x_enc, x_dec)\n",
    "\n",
    "print(output.shape)  # Should output (sequence length, batch size, output dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 1\n",
    "batch_size = 32\n",
    "seq_length = 50\n",
    "horizon= 1\n",
    "# Instantiate the model\n",
    "model = Informer(input_dim=input_size,\n",
    "                 d_model=64,\n",
    "                 num_heads=4,\n",
    "                 d_ff=256,\n",
    "                 num_enc_layers=2,\n",
    "                 num_dec_layers=2,\n",
    "                 output_dim=1,\n",
    "                 seq_len=seq_length,\n",
    "                 device=DEVICE\n",
    ").to(DEVICE)\n",
    "\n",
    "# Generate example data\n",
    "sine_waves, example_input, example_target, time = create_example_data(\n",
    "    batch_size,\n",
    "    seq_length,\n",
    "    input_size,\n",
    "    DEVICE,\n",
    "    horizon=horizon,\n",
    "    trend=True\n",
    ")\n",
    "\n",
    "print(example_input.shape, example_target.shape, time.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "forecast_input = torch.zeros_like(example_target, device=DEVICE\n",
    ")\n",
    "\n",
    "num_epochs = 4000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(example_input,\n",
    "                   forecast_input)\n",
    "    \n",
    "    loss = criterion(output, example_target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 200 == 0:\n",
    "        print(f\"Epoch: {epoch+1:4}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot example data\n",
    "plt.figure()\n",
    "for i in np.random.randint(0, len(example_input), 5):\n",
    "    plt.plot(\n",
    "        time,\n",
    "        sine_waves[i].squeeze().cpu().detach().numpy(),\n",
    "        'b-')\n",
    "    plt.plot(\n",
    "        time[-horizon:],\n",
    "        output[i].squeeze().cpu().detach().numpy(),\n",
    "        'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
