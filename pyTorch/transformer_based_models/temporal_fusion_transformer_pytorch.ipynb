{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The TFT architecture includes:\n",
    "- Input embeddings: Embedding layers for categorical and continuous features.\n",
    "- Variable selection networks: Dynamically select relevant variables.\n",
    "- Gating mechanisms: Control flow between layers.\n",
    "- Temporal attention mechanism: Focus on important time steps.\n",
    "- Fully connected output network: Predict future values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time as timeit\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "print(torch.__version__)\n",
    "\n",
    "DEVICE = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "# DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create example data\n",
    "def create_example_data(batch_size, seq_length, input_size, device):\n",
    "    # Generate random frequencies and phases (0, 10) (0, 2*pi)\n",
    "    frequencies = torch.rand(batch_size) * 10  \n",
    "    phases = torch.rand(batch_size) * 2 * math.pi  \n",
    "\n",
    "    # Create a time vector (+ target)\n",
    "    time = torch.linspace(0, 2 * math.pi, seq_length + 1)\n",
    "\n",
    "    # Generate sine waves (+ target)\n",
    "    sine_waves = torch.zeros(batch_size, seq_length + 1)\n",
    "    for i in range(batch_size):\n",
    "        sine_waves[i] = (torch.sin(frequencies[i] * time + phases[i]))\n",
    "    \n",
    "    # add additive amplitude noise to features\n",
    "    sine_waves[:, :-1] +=  torch.rand(batch_size, seq_length) / 4\n",
    "    \n",
    "    # Split into inputs and targets\n",
    "    sine_waves = sine_waves[:, :, None]\n",
    "    inputs = sine_waves[:, :-1].to(device)\n",
    "    targets = sine_waves[:, -1].to(device)\n",
    "    return sine_waves, inputs, targets, time\n",
    "\n",
    "# Generate example data\n",
    "sine_waves, example_input, example_target, time = create_example_data(\n",
    "    32,\n",
    "    20,\n",
    "    1,\n",
    "    DEVICE)\n",
    "\n",
    "# plot example data\n",
    "plt.figure()\n",
    "\n",
    "for i in np.random.randint(0, len(example_input), 5):\n",
    "    plt.plot(\n",
    "        time,\n",
    "        sine_waves[i].squeeze().cpu().detach().numpy(),\n",
    "        'b-')\n",
    "    plt.plot(\n",
    "        time[-1],\n",
    "        sine_waves[i][-1].squeeze().cpu().detach().numpy(),\n",
    "        'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Temporal Fusion Transformer (TFT) (many to one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Temporal Fusion Transformer TFT\n",
    "class TemporalFusionTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        num_heads: int,\n",
    "        seq_length: int,\n",
    "        output_size: int,\n",
    "        device: torch.device,\n",
    "        dropout: float=0.1\n",
    "    ):\n",
    "\n",
    "        super(TemporalFusionTransformer, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # Embeddings\n",
    "        self.input_embedding = nn.Linear(\n",
    "            input_size,\n",
    "            hidden_size\n",
    "        )\n",
    "\n",
    "        # Temporal attention\n",
    "        self.attention_layer = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # gating mechanism\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                hidden_size,\n",
    "                hidden_size\n",
    "            ),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        # FCL for output\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "        # Positional encoding\n",
    "        self.positional_encoding = self._get_positional_encoding(\n",
    "            seq_length,\n",
    "            hidden_size\n",
    "        )\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        # apply input embedding\n",
    "        x = self.input_embedding(x) + self.positional_encoding\n",
    "        \n",
    "        # apply temporal attention\n",
    "        attn_output, _ = self.attention_layer(\n",
    "            x,\n",
    "            x,\n",
    "            x,\n",
    "        )\n",
    "        \n",
    "        # apply gating mechanism\n",
    "        gated_output = (\n",
    "            self.gate(attn_output) * F.sigmoid(attn_output)\n",
    "        ).sum(dim=1)\n",
    "                 \n",
    "        # apply output layer\n",
    "        output = self.fc(gated_output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def _get_positional_encoding(\n",
    "        self,\n",
    "        seq_length: int,\n",
    "        hidden_size: int\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        position = torch.arange(\n",
    "            0, seq_length\n",
    "        ).unsqueeze(1).to(self.device)\n",
    "        \n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, hidden_size, 2) * (-math.log(10000.0) / hidden_size)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        pe = torch.zeros(\n",
    "            1, seq_length, hidden_size\n",
    "        ).to(self.device)\n",
    "        \n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        return pe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TFT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 30\n",
    "input_size = 1\n",
    "hidden_size = 64\n",
    "num_heads = 4\n",
    "output_size = 1\n",
    "\n",
    "# model = torch.compile(TemporalFusionTransformer(\n",
    "#     input_size,\n",
    "#     hidden_size,\n",
    "#     num_heads,\n",
    "#     seq_length,\n",
    "#     output_size,\n",
    "#     DEVICE\n",
    "# )).to(DEVICE)\n",
    "\n",
    "model = TemporalFusionTransformer(\n",
    "    input_size,\n",
    "    hidden_size,\n",
    "    num_heads,\n",
    "    seq_length,\n",
    "    output_size,\n",
    "    DEVICE\n",
    ").to(DEVICE)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate example data\n",
    "sine_waves, example_input, example_target, time = create_example_data(\n",
    "    32,\n",
    "    seq_length,\n",
    "    input_size,\n",
    "    DEVICE)\n",
    "\n",
    "print(example_input.shape, example_target.shape, time.shape)\n",
    "\n",
    "# plot example data\n",
    "plt.figure()\n",
    "\n",
    "for i in np.random.randint(0, len(example_input), 5):\n",
    "    plt.plot(\n",
    "        time,\n",
    "        sine_waves[i].squeeze().cpu().detach().numpy(),\n",
    "        'b-')\n",
    "    plt.plot(\n",
    "        time[-1],\n",
    "        sine_waves[i][-1].squeeze().cpu().detach().numpy(),\n",
    "        'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the model\n",
    "example_output = model(example_input)\n",
    "\n",
    "print(example_input.shape, example_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 4000\n",
    "\n",
    "start_time = timeit.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(example_input)\n",
    "    \n",
    "    loss = criterion(output, example_target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print(f\"Epoch: {epoch+1:4}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "print(f\"Training time: {timeit.time() - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.plot(\n",
    "        time,\n",
    "        sine_waves[i].squeeze().cpu().detach().numpy(),\n",
    "        'b-')\n",
    "    plt.plot(\n",
    "        time[-1],\n",
    "        output[i].squeeze().cpu().detach().numpy(),\n",
    "        'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Temporal Fusion Transformer (TFT) (many to many)\n",
    "includes:\n",
    "- Variable Selection Network: Dynamically selects important input variables for each time step. Includes gating to enhance interpretability.\n",
    "- Static Embedding: Handles features that do not vary across time (e.g., location or demographic data). These are integrated into the temporal context.\n",
    "- Quantile Forecasting: Provides probabilistic outputs for multiple quantiles (e.g., 10%, 50%, 90%).\n",
    "- Attention with Gating: Combines attention mechanisms with gating to dynamically focus on relevant features and time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableSelectionNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Dynamically selects important variables using gating\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "    ):\n",
    "         \n",
    "        super(VariableSelectionNetwork, self).__init__()\n",
    "        \n",
    "        self.input_layer = nn.Linear(input_size,\n",
    "                                     hidden_size)\n",
    "        \n",
    "        self.gate_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_size,\n",
    "                                      output_size)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        gated_input = self.gate_layer(x) * self.input_layer(x)\n",
    "        \n",
    "        return self.output_layer(gated_input)\n",
    "    \n",
    "\n",
    "class TemporalFusionTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_size: int,\n",
    "        static_input_size: int,\n",
    "        hidden_size: int,\n",
    "        num_heads: int,\n",
    "        seq_length: int,\n",
    "        output_size: int,\n",
    "        device: torch.device,\n",
    "        dropout: float=0.1,\n",
    "        quantiles: tuple=(0.1, 0.5, 0.9)\n",
    "    ):\n",
    "\n",
    "        super(TemporalFusionTransformer, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        # quantile probabilistic forecasting\n",
    "        self.quantiles = quantiles\n",
    "        \n",
    "        # Embeddings\n",
    "        self.input_embedding = nn.Linear(\n",
    "            input_size,\n",
    "            hidden_size\n",
    "        )\n",
    "        self.static_embedding = nn.Linear(\n",
    "            static_input_size,\n",
    "            hidden_size\n",
    "        )\n",
    "        \n",
    "        # variable selection\n",
    "        self.variable_selection = VariableSelectionNetwork(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=hidden_size\n",
    "        )\n",
    "        \n",
    "        # temporal attention\n",
    "        self.attention_layer = nn.MultiheadAttention(\n",
    "            embed_dim=hidden_size,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # gating mechanism\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(\n",
    "                hidden_size,\n",
    "                hidden_size\n",
    "            ),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "        # output layer\n",
    "        self.fc = nn.Linear(\n",
    "            hidden_size,\n",
    "            output_size * len(self.quantiles)\n",
    "        )\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.positional_encoding = self._get_positional_encoding(\n",
    "            seq_length,\n",
    "            hidden_size\n",
    "        )\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        static_inputs: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        # static embeddings\n",
    "        static_context = self.static_embedding(static_inputs)\n",
    "        \n",
    "        # input embeddings\n",
    "        x = self.input_embedding(x) + self.positional_encoding\n",
    "        \n",
    "        # variable selection\n",
    "        x = self.variable_selection(x)\n",
    "        \n",
    "        # temporal attention\n",
    "        attn_output, _ = self.attention_layer(\n",
    "            x,\n",
    "            x,\n",
    "            x,\n",
    "        )\n",
    "        \n",
    "        # gating mechanism\n",
    "        gated_output = self.gate(attn_output) * attn_output\n",
    "   \n",
    "        # gated with static context\n",
    "        gated_with_context = gated_output + static_context.unsqueeze(1)\n",
    "\n",
    "        \n",
    "        # output layer\n",
    "        output = self.fc(gated_with_context)\n",
    "        \n",
    "        # reshape for quantiles\n",
    "        batch_size, seq_length, _ = output.shape\n",
    "        \n",
    "        # [B, T, Q, O]\n",
    "        output = output.view(\n",
    "            batch_size,\n",
    "            seq_length,\n",
    "            len(self.quantiles),\n",
    "            -1\n",
    "        )\n",
    "        \n",
    "        return output\n",
    "        \n",
    "    def _get_positional_encoding(\n",
    "        self,\n",
    "        seq_length: int,\n",
    "        hidden_size: int\n",
    "    ) -> torch.Tensor:\n",
    "\n",
    "        position = torch.arange(\n",
    "            0, seq_length\n",
    "        ).unsqueeze(1).to(self.device)\n",
    "        \n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, hidden_size, 2) * (-math.log(10000.0) / hidden_size)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        pe = torch.zeros(\n",
    "            1, seq_length, hidden_size\n",
    "        ).to(self.device)\n",
    "        \n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        return pe    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 30\n",
    "input_size = 1\n",
    "static_input_size = 2\n",
    "hidden_size = 64\n",
    "num_heads = 4\n",
    "output_size = 1\n",
    "quantiles = (0.1, 0.5, 0.9)\n",
    "\n",
    "model = TemporalFusionTransformer(\n",
    "    input_size,\n",
    "    static_input_size,\n",
    "    hidden_size,\n",
    "    num_heads,\n",
    "    seq_length,\n",
    "    output_size,\n",
    "    DEVICE,\n",
    "    quantiles=quantiles\n",
    ").to(DEVICE)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inputs\n",
    "dynamic_inputs = torch.randn(32, seq_length, input_size).to(DEVICE)\n",
    "static_inputs = torch.zeros(32, static_input_size).to(DEVICE)  # Static inputs for each sample\n",
    "targets = torch.randn(32, seq_length, output_size).to(DEVICE)\n",
    "\n",
    "# Forward pass\n",
    "output = model(dynamic_inputs,\n",
    "               static_inputs)\n",
    "print(output.shape)  # Should output: [32, seq_length, len(quantiles), output_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Quantile loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantileLoss(nn.Module):\n",
    "    def __init__(self,\n",
    "                 quantiles: tuple\n",
    "    ):\n",
    "        super(QuantileLoss, self).__init__()\n",
    "        self.quantiles = quantiles\n",
    "    \n",
    "    def forward(self, preds, target):\n",
    "        loss = 0\n",
    "        \n",
    "        for i, q in enumerate(self.quantiles):\n",
    "            \n",
    "            errors = target - preds[:, :, i]\n",
    "            loss += torch.mean(\n",
    "                torch.max((q - 1) * errors, q * errors)\n",
    "            )\n",
    "        \n",
    "        return loss\n",
    "    \n",
    "criterion = QuantileLoss(quantiles)\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "num_epochs = 1000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(dynamic_inputs,\n",
    "                   static_inputs)\n",
    "    \n",
    "    loss = criterion(output, targets)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch: {epoch+1:4}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporal Fusion Transformer for forecasting (TFT) (many to one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemporalFusionTransformerForecast(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        num_heads: int,\n",
    "        num_layers: int,\n",
    "        agg_method: str=None,\n",
    "        dropout: float=0.1\n",
    "    ):\n",
    "        \n",
    "        super(TemporalFusionTransformerForecast, self).__init__()\n",
    "        \n",
    "        # temporal embeddings\n",
    "        self.input_projection = nn.Linear(\n",
    "            input_size, hidden_size\n",
    "        )\n",
    "        \n",
    "        # temporal processing layers\n",
    "        self.temporal_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=hidden_size,\n",
    "                nhead=num_heads,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # fully connected layes for forecasting\n",
    "        self.gated_residual_network = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "        )\n",
    "        \n",
    "        # output layer\n",
    "        self.output_layer = nn.Linear(\n",
    "            hidden_size, output_size\n",
    "        )\n",
    "        \n",
    "        # aggregation method\n",
    "        match agg_method:\n",
    "            case 'last':\n",
    "                agg_func = lambda x: x[:, -1]\n",
    "            case 'mean':\n",
    "                agg_func = lambda x: torch.mean(x, dim=1)\n",
    "            case 'sum':\n",
    "                agg_func = lambda x: torch.sum(x, dim=1)\n",
    "            case _:\n",
    "                raise ValueError(f\"Invalid aggregation method: {agg_method}\")\n",
    "        self.agg_func = agg_func\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        # project temporal features\n",
    "        x_proj = self.input_projection(x)\n",
    "        \n",
    "        # process temporal sequences\n",
    "        temporal_encoded = self.temporal_encoder(x_proj)\n",
    "        \n",
    "        # aggregate information from temporal features\n",
    "        temporal_context = self.agg_func(temporal_encoded)\n",
    "\n",
    "        # pass through gated residual network\n",
    "        gated_output = self.gated_residual_network(temporal_context)\n",
    "        \n",
    "        # generate forecast\n",
    "        forecast = self.output_layer(gated_output)\n",
    "        \n",
    "        return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 1\n",
    "hidden_size = 64 \n",
    "output_size = 1    \n",
    "num_heads = 4      \n",
    "num_layers = 3\n",
    "dropout = 0.1\n",
    "\n",
    "# Initialize the model\n",
    "model = TemporalFusionTransformerForecast(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=output_size,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    agg_method='last',\n",
    "    dropout=dropout\n",
    ").to(DEVICE)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "batch_size = 32\n",
    "seq_length = 12\n",
    "\n",
    "x_temporal = torch.rand(\n",
    "    batch_size, seq_length, input_size\n",
    ").to(DEVICE)  # Temporal features\n",
    "\n",
    "# Forward pass\n",
    "forecast = model(x_temporal)\n",
    "print(f\"Forecast shape: {forecast.shape}\")  # Expected: [batch_size, output_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate example data\n",
    "sine_waves, example_input, example_target, time = create_example_data(\n",
    "    batch_size,\n",
    "    seq_length,\n",
    "    input_size,\n",
    "    DEVICE)\n",
    "\n",
    "print(example_input.shape, example_target.shape, time.shape)\n",
    "\n",
    "# plot example data\n",
    "plt.figure()\n",
    "\n",
    "for i in np.random.randint(0, len(example_input), 5):\n",
    "    plt.plot(\n",
    "        time,\n",
    "        sine_waves[i].squeeze().cpu().detach().numpy(),\n",
    "        'b-')\n",
    "    plt.plot(\n",
    "        time[-1],\n",
    "        sine_waves[i][-1].squeeze().cpu().detach().numpy(),\n",
    "        'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 4000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(example_input)\n",
    "    \n",
    "    loss = criterion(output, example_target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print(f\"Epoch: {epoch+1:4}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.plot(\n",
    "        time,\n",
    "        sine_waves[i].squeeze().cpu().detach().numpy(),\n",
    "        'b-')\n",
    "    plt.plot(\n",
    "        time[-1],\n",
    "        output[i].squeeze().cpu().detach().numpy(),\n",
    "        'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Temporal Fusion Transformer for forecasting (TFT) (many to one)\n",
    "includes Variable Input Selection Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableSelectionNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Dynamically selects important variables using gating\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "    ):\n",
    "         \n",
    "        super(VariableSelectionNetwork, self).__init__()\n",
    "        \n",
    "        self.input_layer = nn.Linear(input_size,\n",
    "                                     hidden_size)\n",
    "        \n",
    "        self.gate_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_size,\n",
    "                                      output_size)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        gated_input = self.gate_layer(x) * self.input_layer(x)\n",
    "        \n",
    "        return self.output_layer(gated_input)\n",
    "\n",
    "class TemporalFusionTransformerForecast(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        num_heads: int,\n",
    "        num_layers: int,\n",
    "        agg_method: str,\n",
    "        dropout: float=0.1\n",
    "    ):\n",
    "        \n",
    "        super(TemporalFusionTransformerForecast, self).__init__()\n",
    "        \n",
    "        # temporal embeddings\n",
    "        self.input_projection = nn.Linear(\n",
    "            input_size, hidden_size\n",
    "        )\n",
    "        \n",
    "        # variable selection\n",
    "        self.variable_selection = VariableSelectionNetwork(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=hidden_size\n",
    "        )\n",
    "        \n",
    "        # temporal processing layers\n",
    "        self.temporal_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=hidden_size,\n",
    "                nhead=num_heads,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # fully connected layes for forecasting\n",
    "        self.gated_residual_network = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "        )\n",
    "        \n",
    "        # output layer\n",
    "        self.output_layer = nn.Linear(\n",
    "            hidden_size, output_size\n",
    "        )\n",
    "        \n",
    "        # aggregation method\n",
    "        match agg_method:\n",
    "            case 'last':\n",
    "                agg_func = lambda x: x[:, -1]\n",
    "            case 'mean':\n",
    "                agg_func = lambda x: torch.mean(x, dim=1)\n",
    "            case 'sum':\n",
    "                agg_func = lambda x: torch.sum(x, dim=1)\n",
    "            case _:\n",
    "                raise ValueError(f\"Invalid aggregation method: {agg_method}\")\n",
    "        self.agg_func = agg_func\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        # project temporal features\n",
    "        x_proj = self.input_projection(x)\n",
    "        \n",
    "        # variable selection`\n",
    "        x_vs = self.variable_selection(x_proj)\n",
    "        \n",
    "        # process temporal sequences\n",
    "        temporal_encoded = self.temporal_encoder(x_vs)\n",
    "        \n",
    "        # aggregate information from temporal features\n",
    "        temporal_context = self.agg_func(temporal_encoded)\n",
    "\n",
    "        \n",
    "        # pass through gated residual network\n",
    "        gated_output = self.gated_residual_network(temporal_context)\n",
    "        \n",
    "        # generate forecast\n",
    "        forecast = self.output_layer(gated_output)\n",
    "        \n",
    "        return forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 1\n",
    "hidden_size = 64 \n",
    "output_size = 1    \n",
    "num_heads = 4      \n",
    "num_layers = 3\n",
    "dropout = 0.1\n",
    "\n",
    "# Initialize the model\n",
    "model = TemporalFusionTransformerForecast(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=output_size,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    agg_method='last',\n",
    "    dropout=dropout\n",
    ").to(DEVICE)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "batch_size = 32\n",
    "seq_length = 12\n",
    "\n",
    "x_temporal = torch.rand(\n",
    "    batch_size, seq_length, input_size\n",
    ").to(DEVICE)  # Temporal features\n",
    "\n",
    "# Forward pass\n",
    "forecast = model(x_temporal)\n",
    "print(f\"Forecast shape: {forecast.shape}\")  # Expected: [batch_size, output_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate example data\n",
    "sine_waves, example_input, example_target, time = create_example_data(\n",
    "    batch_size,\n",
    "    seq_length,\n",
    "    input_size,\n",
    "    DEVICE)\n",
    "\n",
    "print(example_input.shape, example_target.shape, time.shape)\n",
    "\n",
    "# plot example data\n",
    "plt.figure()\n",
    "\n",
    "for i in np.random.randint(0, len(example_input), 5):\n",
    "    plt.plot(\n",
    "        time,\n",
    "        sine_waves[i].squeeze().cpu().detach().numpy(),\n",
    "        'b-')\n",
    "    plt.plot(\n",
    "        time[-1],\n",
    "        sine_waves[i][-1].squeeze().cpu().detach().numpy(),\n",
    "        'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "num_epochs = 4000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(example_input)\n",
    "    \n",
    "    loss = criterion(output, example_target)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 400 == 0:\n",
    "        print(f\"Epoch: {epoch+1:4}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    plt.plot(\n",
    "        time,\n",
    "        sine_waves[i].squeeze().cpu().detach().numpy(),\n",
    "        'b-'\n",
    "    )\n",
    "    plt.plot(\n",
    "        time[-1],\n",
    "        output[i].squeeze().cpu().detach().numpy(),\n",
    "        'r.'\n",
    "    )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended CI Temporal Fusion Transformer for forecasting (TFT) (many to one)\n",
    "includes Variable Input Selection Network, Gaussian Distribution prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableSelectionNetwork(nn.Module):\n",
    "    \"\"\"\n",
    "    Dynamically selects important variables using gating\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "    ):\n",
    "         \n",
    "        super(VariableSelectionNetwork, self).__init__()\n",
    "        \n",
    "        self.input_layer = nn.Linear(input_size,\n",
    "                                     hidden_size)\n",
    "        \n",
    "        self.gate_layer = nn.Sequential(\n",
    "            nn.Linear(hidden_size, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        self.output_layer = nn.Linear(hidden_size,\n",
    "                                      output_size)\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        gated_input = self.gate_layer(x) * self.input_layer(x)\n",
    "        \n",
    "        return self.output_layer(gated_input)\n",
    "\n",
    "class TemporalFusionTransformerProbabilityForecast(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: int,\n",
    "        output_size: int,\n",
    "        num_heads: int,\n",
    "        num_layers: int,\n",
    "        agg_method: str,\n",
    "        dropout: float=0.1\n",
    "    ):\n",
    "        \n",
    "        super(TemporalFusionTransformerProbabilityForecast, self).__init__()\n",
    "        \n",
    "        # temporal embeddings\n",
    "        self.input_projection = nn.Linear(\n",
    "            input_size, hidden_size\n",
    "        )\n",
    "        \n",
    "        # variable selection\n",
    "        self.variable_selection = VariableSelectionNetwork(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=hidden_size,\n",
    "            output_size=hidden_size\n",
    "        )\n",
    "        \n",
    "        # temporal processing layers\n",
    "        self.temporal_encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(\n",
    "                d_model=hidden_size,\n",
    "                nhead=num_heads,\n",
    "                dropout=dropout,\n",
    "                batch_first=True,\n",
    "            ),\n",
    "            num_layers=num_layers\n",
    "        )\n",
    "        \n",
    "        # fully connected layes for forecasting\n",
    "        self.gated_residual_network = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, hidden_size),\n",
    "        )\n",
    "        \n",
    "        # mean and std layer\n",
    "        self.mean_layer = nn.Linear(\n",
    "            hidden_size, output_size\n",
    "        )\n",
    "        self.std_layer = nn.Linear(\n",
    "            hidden_size, output_size\n",
    "        )\n",
    "        \n",
    "        # aggregation method\n",
    "        match agg_method:\n",
    "            case 'last':\n",
    "                agg_func = lambda x: x[:, -1]\n",
    "            case 'mean':\n",
    "                agg_func = lambda x: torch.mean(x, dim=1)\n",
    "            case 'sum':\n",
    "                agg_func = lambda x: torch.sum(x, dim=1)\n",
    "            case _:\n",
    "                raise ValueError(f\"Invalid aggregation method: {agg_method}\")\n",
    "        self.agg_func = agg_func\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \n",
    "        # project temporal features\n",
    "        x_proj = self.input_projection(x)\n",
    "        \n",
    "        # variable selection`\n",
    "        x_vs = self.variable_selection(x_proj)\n",
    "        \n",
    "        # process temporal sequences\n",
    "        temporal_encoded = self.temporal_encoder(x_vs)\n",
    "        \n",
    "        # aggregate information from temporal features\n",
    "        temporal_context = self.agg_func(temporal_encoded)\n",
    "\n",
    "        \n",
    "        # pass through gated residual network\n",
    "        gated_output = self.gated_residual_network(temporal_context)\n",
    "        \n",
    "        # generate forecast\n",
    "        mean = self.mean_layer(gated_output)\n",
    "        std = self.std_layer(gated_output)\n",
    "        \n",
    "        return mean, std\n",
    "    \n",
    "\n",
    "# Loss Function: Negative Log-Likelihood\n",
    "def gaussian_nll_loss(y_true, mean, std):\n",
    "    \"\"\"\n",
    "    Gaussian negative log-likelihood loss.\n",
    "    y_true: [batch_size, 1] (ground truth)\n",
    "    mean: [batch_size, 1] (predicted mean)\n",
    "    std: [batch_size, 1] (predicted standard deviation)\n",
    "    \"\"\"\n",
    "    variance = std ** 2\n",
    "    output = torch.mean(\n",
    "        0.5 * torch.log(variance) + (y_true - mean) ** 2 / (2 * variance)\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 1\n",
    "hidden_size = 64 \n",
    "output_size = 1    \n",
    "num_heads = 4      \n",
    "num_layers = 3\n",
    "dropout = 0.1\n",
    "\n",
    "# Initialize the model\n",
    "model = TemporalFusionTransformerProbabilityForecast(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    output_size=output_size,\n",
    "    num_heads=num_heads,\n",
    "    num_layers=num_layers,\n",
    "    agg_method='last',\n",
    "    dropout=dropout\n",
    ").to(DEVICE)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data\n",
    "batch_size = 32\n",
    "sequence_length = 12\n",
    "\n",
    "x_temporal = torch.rand(\n",
    "    batch_size, seq_length, input_size\n",
    ").to(DEVICE)\n",
    "\n",
    "# Forward pass\n",
    "mean, std = model(x_temporal)\n",
    "print(f\"Mean shape: {mean.shape}, Std shape: {std.shape}\")\n",
    "\n",
    "# Example usage of loss\n",
    "y_true = torch.rand(\n",
    "    batch_size, 1\n",
    ").to(DEVICE) \n",
    "loss = gaussian_nll_loss(y_true, mean, std)\n",
    "print(f\"Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate example data\n",
    "sine_waves, example_input, example_target, time = create_example_data(\n",
    "    batch_size,\n",
    "    seq_length,\n",
    "    input_size,\n",
    "    DEVICE)\n",
    "\n",
    "print(example_input.shape, example_target.shape, time.shape)\n",
    "\n",
    "# plot example data\n",
    "plt.figure()\n",
    "\n",
    "for i in np.random.randint(0, len(example_input), 5):\n",
    "    plt.plot(\n",
    "        time,\n",
    "        sine_waves[i].squeeze().cpu().detach().numpy(),\n",
    "        'b-')\n",
    "    plt.plot(\n",
    "        time[-1],\n",
    "        sine_waves[i][-1].squeeze().cpu().detach().numpy(),\n",
    "        'r.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "\n",
    "num_epochs = 6000\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    mean, std = model(example_input)\n",
    "    \n",
    "    loss = gaussian_nll_loss(example_target, mean, std)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch + 1) % 500 == 0:\n",
    "        print(f\"Epoch: {epoch+1:4}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    plt.figure()\n",
    "    plt.plot(\n",
    "        time,\n",
    "        sine_waves[i].squeeze().cpu().detach().numpy(),\n",
    "        'b-'\n",
    "    )\n",
    "    plt.plot(\n",
    "        time[-1],\n",
    "        mean[i].squeeze().cpu().detach().numpy(),\n",
    "        'ro'\n",
    "    )\n",
    "    upper = (mean[i].squeeze().cpu().detach().numpy()\n",
    "             + std[i].squeeze().cpu().detach().numpy()\n",
    "    )\n",
    "    lower = (mean[i].squeeze().cpu().detach().numpy()\n",
    "             - std[i].squeeze().cpu().detach().numpy()\n",
    "    )\n",
    "    plt.plot(time[-1], upper, 'r.')\n",
    "    plt.plot(time[-1], lower, 'r.')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Temporal Fusion Network\n",
    "includes variable selection network, lstm with attention, static context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariableSelectionNetwork(nn.Module):\n",
    "    \"\"\"Dynamically selects relevant variables at each time step.\"\"\"\n",
    "    def __init__(self,\n",
    "                 input_size: int,\n",
    "                 hidden_size: int\n",
    "    ) -> torch.Tensor:\n",
    "        super().__init__()\n",
    "        \n",
    "        # gate network\n",
    "        self.gate = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # transformation network\n",
    "        self.transformation = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # softmax\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "         # Variable selection weights\n",
    "        gate_weights = self.softmax(self.gate(inputs))\n",
    "        \n",
    "        # Variable selection\n",
    "        transformed_inputs = self.transformation(inputs)\n",
    "        \n",
    "        # Apply variable selection\n",
    "        return gate_weights * transformed_inputs\n",
    "\n",
    "\n",
    "class TemporalFusionTransformerLSTM(nn.Module):\n",
    "    \"\"\"Simplified Temporal Fusion Transformer with LSTM and variable selection.\"\"\"\n",
    "    def __init__(self,\n",
    "                 input_size,\n",
    "                 static_size,\n",
    "                 lstm_hidden_size,\n",
    "                 attention_heads,\n",
    "                 output_size,\n",
    "                 seq_length\n",
    "    ):\n",
    "        super(TemporalFusionTransformerLSTM, self).__init__()\n",
    "        \n",
    "        # Static Variable Selection\n",
    "        self.static_selection = VariableSelectionNetwork(static_size,\n",
    "                                                         lstm_hidden_size)\n",
    "        \n",
    "        # Temporal Variable Selection\n",
    "        self.temporal_selection = VariableSelectionNetwork(input_size,\n",
    "                                                           lstm_hidden_size)\n",
    "        \n",
    "        # LSTM Encoder\n",
    "        self.lstm = nn.LSTM(lstm_hidden_size,\n",
    "                            lstm_hidden_size,\n",
    "                            batch_first=True)\n",
    "        \n",
    "        # Multi-head Attention\n",
    "        self.attention = nn.MultiheadAttention(lstm_hidden_size,\n",
    "                                               num_heads=attention_heads,\n",
    "                                               batch_first=True)\n",
    "        \n",
    "        # Static Enrichment\n",
    "        self.static_enrichment = nn.Linear(lstm_hidden_size,\n",
    "                                           lstm_hidden_size)\n",
    "        \n",
    "        # Feedforward Network\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden_size,\n",
    "                      lstm_hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(lstm_hidden_size,\n",
    "                      lstm_hidden_size)\n",
    "        )\n",
    "        \n",
    "        # Output layer\n",
    "        self.output_layer = nn.Linear(lstm_hidden_size,\n",
    "                                      output_size)\n",
    "        \n",
    "        # Sequence length\n",
    "        self.seq_length = seq_length\n",
    "    \n",
    "    def forward(self, static_inputs, temporal_inputs):\n",
    "        \n",
    "        # Static variable selection\n",
    "        static_context = self.static_selection(static_inputs)\n",
    "        static_context = static_context.mean(dim=1)  # Aggregate across static features\n",
    "        \n",
    "        # Temporal variable selection\n",
    "        temporal_features = self.temporal_selection(temporal_inputs)\n",
    "        \n",
    "        # LSTM encoder\n",
    "        lstm_output, _ = self.lstm(temporal_features)\n",
    "        \n",
    "        # Static enrichment\n",
    "        enriched_static = self.static_enrichment(static_context).unsqueeze(1).expand(-1, self.seq_length, -1)\n",
    "        enriched_lstm_output = lstm_output + enriched_static\n",
    "        \n",
    "        # Temporal attention\n",
    "        attention_output, _ = self.attention(enriched_lstm_output, enriched_lstm_output, enriched_lstm_output)\n",
    "        \n",
    "        # Feedforward processing\n",
    "        processed_output = self.feedforward(attention_output)\n",
    "        \n",
    "        # Output layer\n",
    "        predictions = self.output_layer(processed_output)\n",
    "        \n",
    "        return predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
