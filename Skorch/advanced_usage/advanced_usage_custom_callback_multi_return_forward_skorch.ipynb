{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(87)\n",
    "torch.cuda.manual_seed(87)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20) (1000,) 0.496\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "np.random.seed(87)\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000, n_features=20, n_informative=10, random_state=87)\n",
    "X, y = X.astype(np.float32), y.astype(np.int64)\n",
    "\n",
    "print(X.shape, y.shape, y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define pytorch classification module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_units=10,\n",
    "        nonlin=F.relu,\n",
    "        dropout=0.5,\n",
    "    ):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        \n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.nonlin = nonlin\n",
    "        \n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        \n",
    "        X = self.nonlin(self.dense1(X))\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing CUSTOM callback\n",
    "Rules:\n",
    "    1. inherit skorch.callbacks.Callback\n",
    "    2. implement atleast one on_ method\n",
    "    3. argments first neuralnet instance, second optionally local data, **kwargs\n",
    "    (4. attributes that should be reset in the initialize method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mock twitter API that tweets epoch validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Callback\n",
    "\n",
    "def tweet(msg):\n",
    "    print('~'*60)\n",
    "    print(\"*tweet*\", msg, \"#skorch #pytorch\")\n",
    "    \n",
    "class AccuracyTweet(Callback):\n",
    "    def __init__(self, min_accuracy):\n",
    "        self.min_accuracy = min_accuracy\n",
    "        \n",
    "    def initialize(self):\n",
    "        self.critical_epoch_ = -1\n",
    "    \n",
    "    # runst after each epoch\n",
    "    def on_epoch_end(self, net, **kwargs):\n",
    "        if self.critical_epoch_ > -1:\n",
    "            return\n",
    "        \n",
    "        if net.history[-1, 'valid_acc'] >= self.min_accuracy:\n",
    "            self.critical_epoch_ = len(net.history)\n",
    "            \n",
    "    # runs after each training\n",
    "    def on_train_end(self, net, **kwargs):\n",
    "        if self.critical_epoch_ < 0:\n",
    "            msg = f\"Accuracy never reached {self.min_accuracy}\"\n",
    "        else:\n",
    "            msg = f\"Accuracy reached {self.min_accuracy} at epoch {self.critical_epoch_}\"\n",
    "            \n",
    "        tweet(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7250\u001b[0m       \u001b[32m0.5050\u001b[0m        \u001b[35m0.7168\u001b[0m  0.0168\n",
      "      2        \u001b[36m0.7169\u001b[0m       0.5000        \u001b[35m0.7069\u001b[0m  0.0112\n",
      "      3        \u001b[36m0.7091\u001b[0m       \u001b[32m0.5150\u001b[0m        \u001b[35m0.6997\u001b[0m  0.0125\n",
      "      4        \u001b[36m0.6983\u001b[0m       \u001b[32m0.5250\u001b[0m        \u001b[35m0.6938\u001b[0m  0.0080\n",
      "      5        \u001b[36m0.6949\u001b[0m       \u001b[32m0.5650\u001b[0m        \u001b[35m0.6886\u001b[0m  0.0056\n",
      "      6        \u001b[36m0.6905\u001b[0m       \u001b[32m0.5850\u001b[0m        \u001b[35m0.6849\u001b[0m  0.0052\n",
      "      7        \u001b[36m0.6806\u001b[0m       \u001b[32m0.6050\u001b[0m        \u001b[35m0.6812\u001b[0m  0.0056\n",
      "      8        0.6845       \u001b[32m0.6500\u001b[0m        \u001b[35m0.6776\u001b[0m  0.0052\n",
      "      9        0.6811       \u001b[32m0.6550\u001b[0m        \u001b[35m0.6743\u001b[0m  0.0060\n",
      "     10        \u001b[36m0.6742\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m0.6712\u001b[0m  0.0059\n",
      "     11        \u001b[36m0.6707\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.6675\u001b[0m  0.0053\n",
      "     12        \u001b[36m0.6706\u001b[0m       \u001b[32m0.6950\u001b[0m        \u001b[35m0.6641\u001b[0m  0.0059\n",
      "     13        \u001b[36m0.6701\u001b[0m       \u001b[32m0.7100\u001b[0m        \u001b[35m0.6612\u001b[0m  0.0056\n",
      "     14        \u001b[36m0.6615\u001b[0m       0.7100        \u001b[35m0.6575\u001b[0m  0.0054\n",
      "     15        0.6633       \u001b[32m0.7350\u001b[0m        \u001b[35m0.6537\u001b[0m  0.0060\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "*tweet* Accuracy reached 0.7 at epoch 13 #skorch #pytorch\n",
      "     16        \u001b[36m0.6580\u001b[0m       \u001b[32m0.7450\u001b[0m        \u001b[35m0.6500\u001b[0m  0.0051\n",
      "     17        \u001b[36m0.6490\u001b[0m       0.7450        \u001b[35m0.6464\u001b[0m  0.0058\n",
      "     18        0.6525       \u001b[32m0.7700\u001b[0m        \u001b[35m0.6424\u001b[0m  0.0051\n",
      "     19        0.6525       0.7650        \u001b[35m0.6387\u001b[0m  0.0053\n",
      "     20        \u001b[36m0.6395\u001b[0m       0.7700        \u001b[35m0.6343\u001b[0m  0.0055\n",
      "     21        0.6433       0.7700        \u001b[35m0.6297\u001b[0m  0.0055\n",
      "     22        \u001b[36m0.6313\u001b[0m       0.7600        \u001b[35m0.6249\u001b[0m  0.0054\n",
      "     23        0.6399       0.7700        \u001b[35m0.6204\u001b[0m  0.0063\n",
      "     24        \u001b[36m0.6233\u001b[0m       \u001b[32m0.7800\u001b[0m        \u001b[35m0.6152\u001b[0m  0.0053\n",
      "     25        0.6272       \u001b[32m0.7900\u001b[0m        \u001b[35m0.6097\u001b[0m  0.0059\n",
      "     26        \u001b[36m0.6211\u001b[0m       0.7900        \u001b[35m0.6043\u001b[0m  0.0049\n",
      "     27        0.6229       0.7900        \u001b[35m0.5990\u001b[0m  0.0051\n",
      "     28        \u001b[36m0.6124\u001b[0m       \u001b[32m0.8050\u001b[0m        \u001b[35m0.5928\u001b[0m  0.0059\n",
      "     29        \u001b[36m0.6070\u001b[0m       0.8050        \u001b[35m0.5871\u001b[0m  0.0053\n",
      "     30        \u001b[36m0.6043\u001b[0m       0.8000        \u001b[35m0.5807\u001b[0m  0.0054\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "*tweet* Accuracy reached 0.7 at epoch 13 #skorch #pytorch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=15,\n",
    "    lr=0.02,\n",
    "    warm_start=True,\n",
    "    callbacks=[AccuracyTweet(min_accuracy=0.7)],\n",
    ")\n",
    "\n",
    "net.fit(X, y)\n",
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple return values from forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_units=5):\n",
    "        super().__init__()\n",
    "        self.num_units = num_units\n",
    "        \n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, num_units),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, X, **kwargs):\n",
    "        return self.encode(X)\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_units=5):\n",
    "        super().__init__()\n",
    "        self.num_units = num_units\n",
    "        \n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(self.num_units, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 20),\n",
    "        )\n",
    "        \n",
    "    def forward(self, X, **kwargs):\n",
    "        return self.decode(X)\n",
    "    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_units=5):\n",
    "        super().__init__()\n",
    "        self.num_units = num_units\n",
    "        \n",
    "        self.encoder = Encoder(self.num_units)\n",
    "        self.decoder = Decoder(self.num_units)\n",
    "        \n",
    "    def forward(self, X, **kwargs):\n",
    "        encoded = self.encoder(X)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Override the get_loss method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderNet(NeuralNetRegressor):\n",
    "    def get_loss(self, y_pred, y_true, *args, **kwargs):\n",
    "        decoded, encoded = y_pred\n",
    "        \n",
    "        loss_reconstruction = super().get_loss(\n",
    "            decoded, y_true, *args, **kwargs)\n",
    "        \n",
    "        loss_l1 = torch.abs(encoded).sum()\n",
    "        \n",
    "        return loss_reconstruction + loss_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1       \u001b[36m29.4691\u001b[0m        \u001b[32m3.8066\u001b[0m  0.0164\n",
      "      2        \u001b[36m3.8723\u001b[0m        \u001b[32m3.7768\u001b[0m  0.0141\n",
      "      3        \u001b[36m3.8420\u001b[0m        \u001b[32m3.7617\u001b[0m  0.0105\n",
      "      4        \u001b[36m3.8259\u001b[0m        \u001b[32m3.7545\u001b[0m  0.0092\n",
      "      5        \u001b[36m3.8178\u001b[0m        \u001b[32m3.7510\u001b[0m  0.0095\n",
      "      6        \u001b[36m3.8139\u001b[0m        \u001b[32m3.7494\u001b[0m  0.0073\n",
      "      7        \u001b[36m3.8120\u001b[0m        \u001b[32m3.7485\u001b[0m  0.0099\n",
      "      8        \u001b[36m3.8110\u001b[0m        \u001b[32m3.7480\u001b[0m  0.0099\n",
      "      9        \u001b[36m3.8105\u001b[0m        \u001b[32m3.7476\u001b[0m  0.0093\n",
      "     10        \u001b[36m3.8103\u001b[0m        \u001b[32m3.7474\u001b[0m  0.0080\n",
      "     11        \u001b[36m3.8101\u001b[0m        \u001b[32m3.7472\u001b[0m  0.0110\n",
      "     12        \u001b[36m3.8100\u001b[0m        \u001b[32m3.7471\u001b[0m  0.0083\n",
      "     13        \u001b[36m3.8100\u001b[0m        \u001b[32m3.7470\u001b[0m  0.0072\n",
      "     14        \u001b[36m3.8099\u001b[0m        \u001b[32m3.7470\u001b[0m  0.0126\n",
      "     15        \u001b[36m3.8099\u001b[0m        \u001b[32m3.7469\u001b[0m  0.0077\n",
      "     16        \u001b[36m3.8099\u001b[0m        \u001b[32m3.7469\u001b[0m  0.0074\n",
      "     17        \u001b[36m3.8099\u001b[0m        \u001b[32m3.7469\u001b[0m  0.0067\n",
      "     18        \u001b[36m3.8099\u001b[0m        \u001b[32m3.7469\u001b[0m  0.0063\n",
      "     19        \u001b[36m3.8099\u001b[0m        \u001b[32m3.7468\u001b[0m  0.0068\n",
      "     20        \u001b[36m3.8099\u001b[0m        \u001b[32m3.7468\u001b[0m  0.0064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class '__main__.AutoEncoderNet'>[initialized](\n",
       "  module_=AutoEncoder(\n",
       "    (encoder): Encoder(\n",
       "      (encode): Sequential(\n",
       "        (0): Linear(in_features=20, out_features=10, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=10, out_features=5, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (decode): Sequential(\n",
       "        (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=10, out_features=20, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = AutoEncoderNet(\n",
    "    AutoEncoder,\n",
    "    module__num_units=5,\n",
    "    lr=0.3,\n",
    "    max_epochs=20\n",
    ")\n",
    "\n",
    "net.fit(X, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting decoder and encoder output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "y_pred = net.predict(X)\n",
    "print(y_pred.shape) # only decoder state is returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 20]) torch.Size([1000, 5])\n"
     ]
    }
   ],
   "source": [
    "# retrieve all predicted batches from Module.forward\n",
    "decoder_pred, encoder_pred = net.forward(X)\n",
    "print(decoder_pred.shape, encoder_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 20]) torch.Size([128, 5])\n"
     ]
    }
   ],
   "source": [
    "# lazy colleciton, one batch at a time\n",
    "for decoder_pred, encoder_pred in net.forward_iter(X):\n",
    "    print(decoder_pred.shape, encoder_pred.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was the encoder sparse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isclose(encoder_pred, torch.zeros_like(encoder_pred)).float().mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
