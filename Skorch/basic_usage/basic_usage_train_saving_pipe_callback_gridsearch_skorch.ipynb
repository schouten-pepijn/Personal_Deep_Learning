{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(87)\n",
    "torch.cuda.manual_seed(87)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create classification data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    random_state=87\n",
    ")\n",
    "X, y = np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)\n",
    "\n",
    "print(X.shape, y.shape, y.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(self, num_units=10, \n",
    "                 nonlin=F.relu, dropout=0.5):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.nonlin(self.dense1(X))\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining and training neural net classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    batch_size=32,\n",
    "    iterator_train__shuffle=True,\n",
    "    # device='mps'\n",
    ")\n",
    "\n",
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions, classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = net.predict(X[:5])\n",
    "y_proba = net.predict_proba(X[:5])\n",
    "print(y_pred, y_proba, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create regression data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X_regr, y_regr = make_regression(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    random_state=87\n",
    ")\n",
    "X_regr, y_regr = (np.array(X_regr, dtype=np.float32),\n",
    "                  np.array(y_regr, dtype=np.float32) / 100)\n",
    "y_regr = y_regr.reshape(-1, 1)\n",
    "\n",
    "print(X_regr.shape, y_regr.shape, y_regr.min(), y_regr.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorModule(nn.Module):\n",
    "    def __init__(self, num_units=10,\n",
    "                 nonlin=F.relu, dropout=0.5):\n",
    "        super(RegressorModule, self).__init__()\n",
    "\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = self.nonlin(self.dense1(X))\n",
    "        X = self.output(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "net_regr = NeuralNetRegressor(\n",
    "    RegressorModule,\n",
    "    criterion=nn.MSELoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    batch_size=32,\n",
    "    iterator_train__shuffle=True,\n",
    "    # device='mps'\n",
    ")\n",
    "net_regr.fit(X_regr, y_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make predictions, regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = net.predict(X_regr[:5])\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle, os\n",
    "\n",
    "save_dir = \"/Users/pepijnschouten/Desktop/Python_Scripts/\" \\\n",
    "    \"Python_scripts_Varia/Deep_Learning/Skorch/models\"\n",
    "\n",
    "file_name = \"basic_usage_model.pkl\"\n",
    "\n",
    "# saving\n",
    "with open(os.path.join(save_dir, file_name), \"wb\") as f:\n",
    "    pickle.dump(net, f)\n",
    "    print(\"Model saved successfully.\")\n",
    "\n",
    "# loading\n",
    "with open(os.path.join(save_dir, file_name), \"rb\") as f:\n",
    "    net = pickle.load(f)\n",
    "    print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving and laoding model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_name = \"basic_usage_model_params.pkl\"\n",
    "\n",
    "# saving\n",
    "net.save_params(os.path.join(save_dir, param_name))\n",
    "\n",
    "# initalizing\n",
    "new_net = NeuralNetClassifier(  \n",
    "    ClassifierModule,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    batch_size=32,\n",
    "    iterator_train__shuffle=True,\n",
    "    # device='mps'\n",
    ").initialize()\n",
    "\n",
    "# loading\n",
    "new_net.load_params(os.path.join(save_dir, param_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage with sklearn Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    batch_size=32,\n",
    "    iterator_train__shuffle=True,\n",
    "    # device='mps'\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('scale', scaler),\n",
    "    ('net', net)\n",
    "])\n",
    "\n",
    "train_history = pipe.fit(X, y)\n",
    "\n",
    "y_proba = pipe.predict_proba(X)\n",
    "y_pred = pipe.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import EpochScoring\n",
    "\n",
    "\"\"\"\n",
    "    Passing a string, None (own scoring), function\n",
    "\"\"\"\n",
    "\n",
    "auc = EpochScoring(scoring='roc_auc', lower_is_better=False)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    batch_size=32,\n",
    "    iterator_train__shuffle=True,\n",
    "    callbacks=[auc],\n",
    "    # device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage with sklearn GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# show network prefixes\n",
    "print(', '.join(net.prefixes_))\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    optimizer=torch.optim.SGD,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    optimizer__momentum=0.9,\n",
    "    batch_size=32,\n",
    "    train_split=False,\n",
    "    verbose=0,\n",
    "    # device='mps'\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    'lr': [0.05, 0.1],\n",
    "    'module__num_units': [10, 20],\n",
    "    'module__dropout': [0., 0.5],\n",
    "    'module__nonlin': [F.relu, F.tanh],\n",
    "    'optimizer__momentum': [0., 0.9],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(net, param_grid=param_grid,\n",
    "                  refit=False,\n",
    "                  cv=3,\n",
    "                  scoring='accuracy',\n",
    "                  verbose=2)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# print best score and params\n",
    "print(gs.best_score_)\n",
    "pprint(gs.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
